"""
Structured schemas for LLM-based code review outputs.

These Pydantic models define the expected structure of LLM responses,
ensuring constrained, parseable outputs.
"""

from enum import Enum
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any


class ReviewRecommendation(str, Enum):
    """Review recommendation types."""
    APPROVE = "APPROVE"
    REQUEST_CHANGES = "REQUEST_CHANGES"
    COMMENT = "COMMENT"


class Category(str, Enum):
    """Finding categories."""
    SECURITY = "Security"
    CODE_QUALITY = "Code Quality"
    PERFORMANCE = "Performance"
    BEST_PRACTICE = "Best Practice"
    TESTING = "Testing"
    DOCUMENTATION = "Documentation"
    STYLE = "Style"


class Severity(str, Enum):
    """Severity levels."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


@dataclass
class ReviewComment:
    """A comment in a review."""
    body: str
    line: Optional[int] = None
    path: Optional[str] = None


@dataclass
class InlineComment:
    """Inline comment on a specific line."""
    file_path: str
    line_number: int
    suggestion: str
    severity: str = "info"


@dataclass
class Finding:
    """A single finding in the review."""
    category: str
    severity: str
    title: str
    description: str
    suggestion: Optional[str] = None
    file_path: Optional[str] = None
    line_number: Optional[int] = None


@dataclass
class CodeReview:
    """Structured code review output."""
    summary: str
    risk_score: float
    recommendation: ReviewRecommendation
    findings: List[Finding] = field(default_factory=list)
    inline_comments: List[InlineComment] = field(default_factory=list)
    metrics: Optional[Dict[str, Any]] = None
    
    def to_markdown(self) -> str:
        """Convert review to markdown format for GitHub."""
        lines = []
        
        # Header
        lines.append("## PR Analysis Summary\n")
        
        # Risk Score with visual indicator
        risk_label = self._get_risk_label(self.risk_score)
        lines.append(f"**Risk Score:** {self.risk_score:.1f}/10 ({risk_label})")
        lines.append(f"**Recommendation:** {self._format_recommendation()}\n")
        
        # Summary
        lines.append("### Overview")
        lines.append(self.summary)
        lines.append("")
        
        # Findings by severity
        if self.findings:
            lines.append("### Findings\n")
            findings_by_severity = self._group_findings_by_severity()
            
            for severity in ["critical", "high", "medium", "low", "info"]:
                severity_findings = findings_by_severity.get(severity, [])
                if severity_findings:
                    lines.append(f"#### {severity.capitalize()}\n")
                    
                    for finding in severity_findings:
                        lines.append(f"- [{finding.category}] {finding.title}")
                        lines.append(f"  Description: {finding.description}")
                        if finding.suggestion:
                            lines.append(f"  Suggestion: {finding.suggestion}")
                        if finding.file_path:
                            lines.append(f"  Location: {finding.file_path}:{finding.line_number}")
                        lines.append("")
        else:
            lines.append("### Findings\n")
            lines.append("No issues detected.\n")
        
        # Metrics if available
        if self.metrics:
            lines.append("### Metrics\n")
            for key, value in self.metrics.items():
                lines.append(f"- {key}: {value}")
            lines.append("")
        
        # Inline comments summary
        if self.inline_comments:
            lines.append(f"### Code Comments ({len(self.inline_comments)})\n")
            lines.append(f"See inline comments on the changed files for detailed feedback.\n")
        
        # Footer
        lines.append("---")
        lines.append("Generated by PR Review Agent")
        
        return "\n".join(lines)
    
    def _get_risk_label(self, score: float) -> str:
        if score < 2:
            return "LOW"
        elif score < 4:
            return "MEDIUM"
        elif score < 7:
            return "HIGH"
        else:
            return "CRITICAL"
    
    def _format_recommendation(self) -> str:
        if self.recommendation == ReviewRecommendation.APPROVE:
            return "APPROVE"
        elif self.recommendation == ReviewRecommendation.REQUEST_CHANGES:
            return "REQUEST CHANGES"
        else:
            return "COMMENT"
    
    def _group_findings_by_severity(self) -> Dict[str, List[Finding]]:
        grouped = {}
        for finding in self.findings:
            if finding.severity not in grouped:
                grouped[finding.severity] = []
            grouped[finding.severity].append(finding)
        return grouped