# ==============================================================================
# PR Review Agent - Environment Configuration
# ==============================================================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control

# ==============================================================================
# GitHub App Configuration
# ==============================================================================
# Your GitHub App ID (find in GitHub App settings)
GITHUB_APP_ID=your_app_id_here

# Installation ID (get from installing the app on a repository)
GITHUB_INSTALLATION_ID=your_installation_id_here

# Webhook secret (set when configuring webhooks in GitHub App settings)
GITHUB_WEBHOOK_SECRET=your_webhook_secret_here

# Path to GitHub App private key (.pem file)
# Can be absolute path or relative to project root
GITHUB_PRIVATE_KEY=key only including rsa

# Alternatively, you can provide the private key directly (base64 encoded)
# GITHUB_PRIVATE_KEY_BASE64=your_base64_encoded_private_key

# ==============================================================================
# LLM Provider Configuration
# ==============================================================================
# Choose your LLM provider: openai, anthropic, azure, or local
LLM_PROVIDER=openai

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.3
LLM_MODEL=gpt-4o-mini

# Anthropic Configuration (if using Claude)
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_MODEL=claude-3-sonnet-20240229
# ANTHROPIC_MAX_TOKENS=4096

# Azure OpenAI Configuration (if using Azure)
# AZURE_OPENAI_API_KEY=your_azure_key_here
# AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT_NAME=your_deployment_name
# AZURE_OPENAI_API_VERSION=2024-02-01

# ==============================================================================
# Agent Configuration
# ==============================================================================
# Maximum iterations for agentic reasoning
MAX_AGENT_ITERATIONS=3

# Confidence threshold for publishing reviews (0.0 - 1.0)
AGENT_CONFIDENCE_THRESHOLD=0.75

# Enable/disable agentic refinement
ENABLE_AGENT_REFINEMENT=true

# ==============================================================================
# Static Analysis Configuration
# ==============================================================================
# Enable/disable specific static analysis tools
ENABLE_FLAKE8=true
ENABLE_PYLINT=true
ENABLE_BANDIT=true
ENABLE_COMPLEXITY_ANALYSIS=true

# Complexity thresholds
COMPLEXITY_THRESHOLD=10
MAINTAINABILITY_INDEX_THRESHOLD=65

# ==============================================================================
# Risk Analysis Configuration
# ==============================================================================
# Thresholds for risk scoring
LARGE_PR_FILE_THRESHOLD=15
LARGE_PR_LINES_THRESHOLD=500
HIGH_COMPLEXITY_THRESHOLD=15

# Critical file patterns (comma-separated regex patterns)
CRITICAL_FILE_PATTERNS=["auth","security","payment","database","config"]

# ==============================================================================
# Review Configuration
# ==============================================================================
# Auto-approve PRs with low risk score (0.0 - 10.0)
# Set to 0 to disable auto-approval
AUTO_APPROVE_THRESHOLD=3.0

# Maximum number of inline comments per file
MAX_COMMENTS_PER_FILE=10

# Review comment style: conversational, formal, concise
REVIEW_COMMENT_STYLE=conversational

# ==============================================================================
# Storage Configuration (AWS S3)
# ==============================================================================
# AWS credentials for S3 storage
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_REGION=us-east-1

# S3 bucket for storing review artifacts and logs
S3_BUCKET_NAME=pr-review-agent-storage

# Enable/disable S3 storage
ENABLE_S3_STORAGE=false

# ==============================================================================
# Observability Configuration
# ==============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Enable structured logging (JSON format)
STRUCTURED_LOGGING=true

# Enable performance metrics collection
ENABLE_METRICS=true

# Metrics export endpoint (Prometheus, CloudWatch, etc.)
# METRICS_ENDPOINT=http://localhost:9090

# Sentry DSN for error tracking (optional)
# SENTRY_DSN=your_sentry_dsn_here

# ==============================================================================
# Application Configuration
# ==============================================================================
# FastAPI application host and port
APP_HOST=0.0.0.0
APP_PORT=8000

# Number of worker processes (for production)
WORKERS=4

# Enable debug mode (DO NOT use in production)
DEBUG=false

# API rate limiting
RATE_LIMIT_PER_MINUTE=60

# Webhook processing timeout (seconds)
WEBHOOK_TIMEOUT=300

# ==============================================================================
# Database Configuration (Optional - for future persistence)
# ==============================================================================
# DATABASE_URL=postgresql://user:password@localhost:5432/pr_review_agent
# DATABASE_POOL_SIZE=10
# DATABASE_MAX_OVERFLOW=20

# ==============================================================================
# Cache Configuration (Optional - Redis for caching)
# ==============================================================================
# REDIS_URL=redis://localhost:6379/0
# CACHE_TTL=3600

# ==============================================================================
# Feature Flags
# ==============================================================================
# Enable experimental features
ENABLE_EXPERIMENTAL_FEATURES=false

# Enable parallel file analysis
ENABLE_PARALLEL_ANALYSIS=true

# Enable LLM caching (reduces API costs)
ENABLE_LLM_CACHING=true

# Enable test coverage integration
ENABLE_COVERAGE_INTEGRATION=false

# ==============================================================================
# Security Configuration
# ==============================================================================
# CORS allowed origins (comma-separated)
CORS_ALLOWED_ORIGINS=*

# API key for internal services (optional)
# INTERNAL_API_KEY=your_internal_api_key

# Enable webhook signature verification
VERIFY_WEBHOOK_SIGNATURE=true

# ==============================================================================
# Development / Testing
# ==============================================================================
# Enable testing mode
TESTING=false

# Mock LLM responses (for testing without API costs)
MOCK_LLM_RESPONSES=false

# Mock GitHub API (for testing without GitHub access)
MOCK_GITHUB_API=false
VERIFY_WEBHOOK_SIGNATURE=false
S3_ENABLED=false
